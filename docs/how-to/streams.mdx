---
id: streams
title: Streams
---

Modern reactive applications are often built upon an event-driven paradigm. One of Zef's main goals is to make building reactive, distributed applications both simpler and easier within the Python / Julia / C++ (more languages to come) ecosystem both simpler and easier. 

There are multiple paradigms and approached tackling the problem distributed computation e.g. (actor model, CSP such as implemented in Go or Clojure's Core/Async, "death star construction" based on http and polling as partially practiced by Netflix and AWS). 

The paradigm that Zef tries to implement in a user-friendly manner is the observer pattern (see e.g. ReactiveX). This can be understood as counterpart to the iterator pattern (e.g. generators/iterables in Python). Whereas the Iterator pattern is pull-based, the observer pattern is push based ("In the observer pattern, the producer iterates you" - Jafar Husain). The core data structure is the observable: a collections over time. Although the term is heavily overloaded, we refer to observables as **Streams** in Zef (also leaning on the common usage by Kafka, Pulsar, AWS Kinesis, etc.).

The difference to Kafka et al. is that in Zef, Streams are a very light weight data structure that you can build your application and functions around, rather than your service plugging into an external stream. It allows you to build event-driven applications in the small, e.g. even within single tiny program running within a process. This is in contrast to a large effort that it takes when setting up a Kafka cluster.

:::info How does ReactiveZ differ form ReactiveX?

:::








##  Yin & Yang
What exactly is a suitable counterpart to the `initial_value` stored in a LazyValue?
Let us explore this question by going through the analogues of these two related data structures for some basic examples.
Let us quickly recap the analogies:
1. **Iterables** and **Streams**
1. **Lazy Values** and **Awaitables**


`for_each` is to LazyValue what `subscribe` is to Stream
```python
[1,2,3]       | map[lambda x: 2*x] | for_each[print]        # lazy sequence / iterable
my_int_stream | map[lambda x: 2*x] | subscribe[print]       # stream
```
The computation for the upper case is driven by the consumer, i.e. it is pull based. The computation can be performed on the fly and will be completed before the program continues to the next line. 'next' is called by the consumer until the iterator raises a `StopIterationError` (at least in Python, but similar constructs exist in other languages). 

For streams, the events are pushed in by the producer (push-based). The consumer (the thread running the above code) cannot wait around for the stream to complete (the producer calling `on_complete`). This could take much too long and therefore the thread does not block on that statement, but hooks up the callback function provided in `subscribe` in the program state (mutating), such that any item emitted from `my_int_stream` is passed through the functional pipeline and the final item is executed using the provided callback function. 

What is the structure of the dataflow? We can think of the source stream being controlled by the effects system (imperative shell), dealing with all the potential errors that may happen over the network or across threads.
The following functional pipeline in the middle deals with the coordination of the computation and should consist of largely of pure functions (functional core).
The final part can be thought of being part of the imperative shell again: the callback function inside subscribe always causes side effects (why else would we bother running it if its return value is ignored?).


```python
[1,2,3]       | map[lambda x: 2*x] | last | print | run
my_int_stream | map[lambda x: 2*x] | last | print | run
```
This is ver


```python
[1,2,3]       | map[lambda x: 2*x] | collect
my_int_stream | map[lambda x: 2*x] | collect        # similar to await
```


LazyValue:  (initial_value, el_ops)

Awaitable:  (concrete_source, el_ops)              # source: a "concrete Awaitable?" 

